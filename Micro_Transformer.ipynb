{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dye6dFTge35a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Input embeddings\n",
        "class InputEmbeddings(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super(InputEmbeddings, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch, seq_len) --> (batch, seq_len, d_model)\n",
        "        return self.embed(x)*np.sqrt(self.d_model)\n",
        "\n",
        "#positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, seq_len):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.seq_len = seq_len\n",
        "        pe = torch.zeros(seq_len, d_model)\n",
        "        position=torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) #(seq,1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe) # useful when we saving the model.\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False) # (batch, seq_len, d_model)\n",
        "        return x\n",
        "\n",
        "class ProjectionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, vocab_size) -> None:\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x) -> None:\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, vocab_size)\n",
        "        return self.proj(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OYLYcj5-wngm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feed forward network\n",
        "class FFN(nn.Module):\n",
        "  def __init__(self, d_model, d_ff, dropout):\n",
        "    super(FFN, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.d_ff = d_ff\n",
        "    self.dropout = dropout\n",
        "    self.model=nn.Sequential(\n",
        "        nn.Linear(d_model, d_ff),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(d_ff, d_model)\n",
        "\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "\n",
        "#skip connection for vanishing gradinet problem, to transfer strong signal.\n",
        "class ResidualConnection(nn.Module):\n",
        "\n",
        "        def __init__(self, d_model):\n",
        "            super().__init__()\n",
        "            self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        def forward(self, x, sublayer):\n",
        "            return self.norm(x + sublayer(x))\n"
      ],
      "metadata": {
        "id": "H2DxsfDOSp0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Attention block\n",
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self, d_model):\n",
        "    super(SelfAttention, self).__init__()\n",
        "    self.w_q = nn.Linear(d_model, d_model, bias=False) # Wq\n",
        "    self.w_k = nn.Linear(d_model, d_model, bias=False) # Wk\n",
        "    self.w_v = nn.Linear(d_model, d_model, bias=False) # Wv\n",
        "  def forward(self,q,k,v,flag):\n",
        "    Q = self.w_q(q)\n",
        "    K = self.w_k(k)\n",
        "    V = self.w_v(v)\n",
        "    if flag=='Encoder': #checking encoder or decoder\n",
        "      print('In encoder')\n",
        "      attention_value_matrix=F.scaled_dot_product_attention(Q,K,V,is_causal=False)\n",
        "\n",
        "    elif flag=='Decoder':\n",
        "      attention_value_matrix=F.scaled_dot_product_attention(Q,K,V,is_causal=True)\n",
        "      print('In decoder')\n",
        "    else:\n",
        "      print('Error')\n",
        "    return attention_value_matrix\n"
      ],
      "metadata": {
        "id": "PQLXCwIikztP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, d_model, d_ff, dropout):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    self.self_attention = SelfAttention(d_model)\n",
        "    self.ffn = FFN(d_model, d_ff, dropout)\n",
        "    self.residual_connections = nn.ModuleList([ResidualConnection(d_model) for _ in range(2)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.residual_connections[0](x, lambda x: self.self_attention(x,x,x,'Encoder'))\n",
        "    x = self.residual_connections[1](x, self.ffn)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "DwfSHYCuGT-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, d_model, d_ff, dropout):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.encoderlayer = EncoderLayer(d_model, d_ff, dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoderlayer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "6fOEvG9LOfN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder block\n",
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, d_model, d_ff, dropout):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "    self.self_attention = SelfAttention(d_model)\n",
        "    self.cross_attention = SelfAttention(d_model)\n",
        "    self.ffn = FFN(d_model, d_ff, dropout)\n",
        "    self.residual_connections = nn.ModuleList([ResidualConnection(d_model) for _ in range(3)])\n",
        "\n",
        "  def forward(self, x,encoder_output):\n",
        "    x = self.residual_connections[0](x, lambda x: self.self_attention(x,x,x,'Decoder'))\n",
        "    x = self.residual_connections[1](x, lambda x: self.cross_attention(x,encoder_output,encoder_output,'Encoder'))\n",
        "    x = self.residual_connections[2](x, self.ffn)\n",
        "    return x"
      ],
      "metadata": {
        "id": "uHbF-AOdVbYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, d_model, d_ff, dropout):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.decoderlayer = DecoderBlock(d_model, d_ff, dropout)\n",
        "\n",
        "  def forward(self, x,encoder_output):\n",
        "    x = self.decoderlayer(x,encoder_output)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ugctbF0g6Y-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Block\n",
        "torch.manual_seed(0)\n",
        "\n",
        "#Sample input\n",
        "src_seq_len = 5\n",
        "target_seq_len = 6\n",
        "src_seq = torch.randint(0, 1000, (1, src_seq_len))  # Batch size 1, sequence length 10, random vocabulary indices\n",
        "target_seq = torch.randint(0, 1500, (1, target_seq_len)) # Batch size 1, sequence length 10, random vocabulary indices\n",
        "print(src_seq)\n",
        "print(target_seq)\n",
        "print('#######################################################################')\n",
        "\n",
        "\n",
        "# vocab and model dim\n",
        "src_vocab_size = 1000\n",
        "target_vocab_size = 1500\n",
        "d_model = 4\n",
        "\n",
        "# Instantiate InputEmbeddings\n",
        "src_input_embeddings = InputEmbeddings(src_vocab_size, d_model)\n",
        "target_input_embeddings = InputEmbeddings(target_vocab_size, d_model)\n",
        "\n",
        "#positional encodings for source and target\n",
        "src_positional_encoding = PositionalEncoding(d_model, src_seq_len)\n",
        "target_positional_encoding = PositionalEncoding(d_model, target_seq_len)\n",
        "\n",
        "# Generate input embeddings\n",
        "src_embeddings = src_input_embeddings(src_seq)\n",
        "target_embeddings = target_input_embeddings(target_seq)\n",
        "\n",
        "# Add positional encoding\n",
        "src_encoded_input = src_positional_encoding(src_embeddings)\n",
        "target_encoded_input = target_positional_encoding(target_embeddings)\n",
        "\n",
        "# feed forward neural network configs\n",
        "d_ff = 2048\n",
        "dropout = 0.1\n",
        "\n",
        "#Instantiate Encoder\n",
        "encoder_layer = Encoder(d_model, d_ff, dropout)\n",
        "\n",
        "# Pass encoded input through the encoder layer\n",
        "encoder_output = encoder_layer(src_encoded_input)\n",
        "\n",
        "# Print the output of encoder shape\n",
        "print(\"Output shape encoder:\", encoder_output.shape)\n",
        "print(encoder_output)\n",
        "print('#######################################################################')\n",
        "#Instantiate decoder\n",
        "decoder_layer = Decoder(d_model, d_ff, dropout)\n",
        "\n",
        "# Pass encoded input through the decoder layer\n",
        "decoder_output = decoder_layer(target_encoded_input,encoder_output)\n",
        "\n",
        "# Print the output of decoder shape\n",
        "print(\"Output shape decoder:\", decoder_output.shape)\n",
        "print(decoder_output)\n",
        "print('#######################################################################')\n",
        "#projection layer\n",
        "projection_layer = ProjectionLayer(d_model, target_vocab_size)\n",
        "\n",
        "# Pass decoder output through the projection layer\n",
        "proj_output = projection_layer(decoder_output)\n",
        "\n",
        "# Print the output shape\n",
        "print(\"Output shape projection:\", proj_output.shape)\n",
        "print(proj_output)\n",
        "print('#######################################################################')\n",
        "#apply softmax on projected output\n",
        "softmax_output = F.softmax(proj_output, dim=-1)\n",
        "print(f'logits_output_shape : {softmax_output.shape}')\n",
        "print(f'logits : {softmax_output}')\n",
        "print('#######################################################################')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0baWLe-ZOrFe",
        "outputId": "f88196d9-ec04-4341-839c-c9abf651f6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 44, 239, 933, 760, 963]])\n",
            "tensor([[ 879,  427, 1003,  997,  183,  101]])\n",
            "#######################################################################\n",
            "In encoder\n",
            "Output shape encoder: torch.Size([1, 5, 4])\n",
            "tensor([[[-4.2172e-01,  7.7449e-01, -1.4334e+00,  1.0806e+00],\n",
            "         [ 1.5940e+00,  1.0219e-01, -9.1965e-01, -7.7652e-01],\n",
            "         [ 9.0996e-01, -1.6295e+00,  7.9224e-04,  7.1876e-01],\n",
            "         [-8.0718e-01,  1.4484e+00,  4.0221e-01, -1.0434e+00],\n",
            "         [ 1.3678e+00, -1.4276e+00, -1.8148e-01,  2.4123e-01]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "#######################################################################\n",
            "In decoder\n",
            "In encoder\n",
            "Output shape decoder: torch.Size([1, 6, 4])\n",
            "tensor([[[ 1.0217,  0.3031, -1.6590,  0.3342],\n",
            "         [-0.4455, -0.7246, -0.5534,  1.7234],\n",
            "         [ 0.3227, -0.7446, -1.0643,  1.4861],\n",
            "         [-0.6521, -1.2934,  0.9045,  1.0410],\n",
            "         [-0.8802,  1.0959, -1.1081,  0.8924],\n",
            "         [-1.1076,  0.1991,  1.5315, -0.6230]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "#######################################################################\n",
            "Output shape projection: torch.Size([1, 6, 1500])\n",
            "tensor([[[-0.4708,  1.3450, -0.5359,  ..., -0.1485,  0.5436,  0.8637],\n",
            "         [ 0.8474,  1.0143, -1.0368,  ..., -0.6276, -0.5009,  0.8098],\n",
            "         [ 0.3806,  1.2315, -1.1980,  ..., -0.7038, -0.2094,  1.1291],\n",
            "         [ 1.2035,  0.0786, -0.5396,  ..., -0.7901, -1.2925,  0.7841],\n",
            "         [ 0.3870,  1.2086, -0.0162,  ...,  0.3992,  0.3865, -0.1952],\n",
            "         [ 0.8878, -0.5391,  1.0384,  ...,  0.1847, -0.9695, -0.2739]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "#######################################################################\n",
            "logits_output_shape : torch.Size([1, 6, 1500])\n",
            "logits : tensor([[[0.0003, 0.0021, 0.0003,  ..., 0.0005, 0.0009, 0.0013],\n",
            "         [0.0013, 0.0015, 0.0002,  ..., 0.0003, 0.0003, 0.0012],\n",
            "         [0.0008, 0.0019, 0.0002,  ..., 0.0003, 0.0004, 0.0017],\n",
            "         [0.0018, 0.0006, 0.0003,  ..., 0.0002, 0.0001, 0.0012],\n",
            "         [0.0008, 0.0018, 0.0005,  ..., 0.0008, 0.0008, 0.0004],\n",
            "         [0.0013, 0.0003, 0.0015,  ..., 0.0006, 0.0002, 0.0004]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "#######################################################################\n"
          ]
        }
      ]
    }
  ]
}